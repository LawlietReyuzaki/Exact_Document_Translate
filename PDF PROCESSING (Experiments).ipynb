{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec625b2f",
   "metadata": {},
   "source": [
    "# for slanting text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5aaaaf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extracted and saved to extracted_data.json\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "import math\n",
    "\n",
    "def extract_pdf_data(pdf_path, output_json):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    extracted_data = []\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        page_data = {\n",
    "            \"page_number\": page_num + 1,\n",
    "            \"width\": page.rect.width,\n",
    "            \"height\": page.rect.height,\n",
    "            \"text_blocks\": []\n",
    "        }\n",
    "\n",
    "        text_instances = page.get_text(\"dict\")\n",
    "        \n",
    "        for block in text_instances[\"blocks\"]:\n",
    "            block_data = {\"lines\": []}\n",
    "            \n",
    "            for line in block[\"lines\"]:\n",
    "                line_data = {\"spans\": []}\n",
    "                \n",
    "                # Extract the direction vector (cosine, sine)\n",
    "                direction = line.get(\"dir\", (1, 0))\n",
    "                cosine, sine = direction\n",
    "\n",
    "                # Calculate the rotation angle in radians\n",
    "                angle_rad = math.atan2(sine, cosine)\n",
    "\n",
    "                # Convert the angle to degrees\n",
    "                #angle_deg = math.degrees(angle_rad)\n",
    "                \n",
    "                \n",
    "                \n",
    "                angle_deg = -math.degrees(angle_rad)  # Invert the angle\n",
    "\n",
    "\n",
    "                for span in line[\"spans\"]:\n",
    "                    span_data = {\n",
    "                        \"text\": span[\"text\"],\n",
    "                        \"font\": span[\"font\"],\n",
    "                        \"font_size\": span[\"size\"],\n",
    "                        \"bbox\": span[\"bbox\"],  # (x0, y0, x1, y1)\n",
    "                        \"rotation\": angle_deg,  # Rotation angle in degrees\n",
    "                        \"color\": span[\"color\"]\n",
    "                    }\n",
    "                    line_data[\"spans\"].append(span_data)\n",
    "                \n",
    "                block_data[\"lines\"].append(line_data)\n",
    "            \n",
    "            page_data[\"text_blocks\"].append(block_data)\n",
    "        \n",
    "        extracted_data.append(page_data)\n",
    "\n",
    "    # Save to JSON file\n",
    "    with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(extracted_data, f, indent=4)\n",
    "\n",
    "    print(f\"Data extracted and saved to {output_json}\")\n",
    "\n",
    "# Run extraction\n",
    "extract_pdf_data(\"Comic _Ghosts Book 1 Excerpt-6.pdf\", \"extracted_data.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ea2829",
   "metadata": {},
   "source": [
    "# without slant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42f705a",
   "metadata": {},
   "source": [
    "##### the following is the best font processing part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "62865d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data extracted and saved to extracted_data.json\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "import math\n",
    "\n",
    "def extract_pdf_data(pdf_path, output_json):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    extracted_data = []\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        page_data = {\n",
    "            \"page_number\": page_num + 1,\n",
    "            \"width\": page.rect.width,\n",
    "            \"height\": page.rect.height,\n",
    "            \"text_blocks\": []\n",
    "        }\n",
    "\n",
    "        text_instances = page.get_text(\"dict\")\n",
    "\n",
    "        for block in text_instances[\"blocks\"]:\n",
    "            block_data = {\"lines\": []}\n",
    "\n",
    "            # ✅ Check if \"lines\" key exists before accessing\n",
    "            if \"lines\" not in block:\n",
    "                continue  # Skip blocks that don't contain text lines\n",
    "\n",
    "            for line in block[\"lines\"]:\n",
    "                line_data = {\"spans\": []}\n",
    "\n",
    "                for span in line[\"spans\"]:\n",
    "                    # ✅ Extract text rotation and invert the slant\n",
    "                    if \"dir\" in span:  # Check if direction vector exists\n",
    "                        cosine, sine = span[\"dir\"]\n",
    "                        angle_rad = math.atan2(sine, cosine)\n",
    "                        angle_deg = -math.degrees(angle_rad)  # Inverted angle\n",
    "                    else:\n",
    "                        angle_deg = 0  # Default to 0 if no direction found\n",
    "\n",
    "                    span_data = {\n",
    "                        \"text\": span[\"text\"],\n",
    "                        \"font\": span[\"font\"],\n",
    "                        \"font_size\": span[\"size\"]-0.5,\n",
    "                        \"bbox\": span[\"bbox\"],  # (x0, y0, x1, y1)\n",
    "                        \"rotation\": angle_deg,  # Use inverted angle\n",
    "                        \"color\": span[\"color\"]\n",
    "                    }\n",
    "                    line_data[\"spans\"].append(span_data)\n",
    "\n",
    "                block_data[\"lines\"].append(line_data)\n",
    "\n",
    "            page_data[\"text_blocks\"].append(block_data)\n",
    "\n",
    "        extracted_data.append(page_data)\n",
    "\n",
    "    # Save to JSON file\n",
    "    with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(extracted_data, f, indent=4)\n",
    "\n",
    "    print(f\"✅ Data extracted and saved to {output_json}\")\n",
    "\n",
    "# Run extraction\n",
    "#extract_pdf_data(\"SBI Innovative Opportunities Fund_One Pager (2) (2).pdf\", \"extracted_data.json\")\n",
    "extract_pdf_data(\"Aatmanirbhar Org.pdf\", \"extracted_data.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312c84da",
   "metadata": {},
   "source": [
    "#### extracting font color and determining which text is bold or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d82ca23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data extracted and saved to extracted_data.json\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "import math\n",
    "\n",
    "def extract_pdf_data(pdf_path, output_json):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    extracted_data = []\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        page_data = {\n",
    "            \"page_number\": page_num + 1,\n",
    "            \"width\": page.rect.width,\n",
    "            \"height\": page.rect.height,\n",
    "            \"text_blocks\": []\n",
    "        }\n",
    "\n",
    "        text_instances = page.get_text(\"dict\")\n",
    "\n",
    "        for block in text_instances[\"blocks\"]:\n",
    "            block_data = {\"lines\": []}\n",
    "\n",
    "            # ✅ Check if \"lines\" key exists before accessing\n",
    "            if \"lines\" not in block:\n",
    "                continue  # Skip non-text blocks (like images)\n",
    "\n",
    "            for line in block[\"lines\"]:\n",
    "                line_data = {\"spans\": []}\n",
    "\n",
    "                for span in line[\"spans\"]:\n",
    "                    # ✅ Extract text rotation and invert the slant\n",
    "                    if \"dir\" in span:  # Check if direction vector exists\n",
    "                        cosine, sine = span[\"dir\"]\n",
    "                        angle_rad = math.atan2(sine, cosine)\n",
    "                        angle_deg = -math.degrees(angle_rad)  # Inverted angle\n",
    "                    else:\n",
    "                        angle_deg = 0  # Default to 0 if no direction found\n",
    "\n",
    "                    # ✅ Extract text color and convert to RGB\n",
    "                    color_int = span[\"color\"]\n",
    "                    r = (color_int >> 16) & 0xFF  # Extract red\n",
    "                    g = (color_int >> 8) & 0xFF   # Extract green\n",
    "                    b = color_int & 0xFF          # Extract blue\n",
    "                    text_color = (r, g, b)        # Store as RGB tuple\n",
    "\n",
    "                    # ✅ Check if text is bold\n",
    "                    is_bold = \"bold\" in span[\"font\"].lower()  # Case-insensitive check\n",
    "\n",
    "                    span_data = {\n",
    "                        \"text\": span[\"text\"],\n",
    "                        \"font\": span[\"font\"],\n",
    "                        \"font_size\": span[\"size\"]-0.5,\n",
    "                        \"bbox\": span[\"bbox\"],  # (x0, y0, x1, y1)\n",
    "                        \"rotation\": angle_deg,  # Use inverted angle\n",
    "                        \"color\": text_color,  # RGB format\n",
    "                        \"bold\": is_bold  # Boolean (True if bold, else False)\n",
    "                    }\n",
    "                    line_data[\"spans\"].append(span_data)\n",
    "\n",
    "                block_data[\"lines\"].append(line_data)\n",
    "\n",
    "            page_data[\"text_blocks\"].append(block_data)\n",
    "\n",
    "        extracted_data.append(page_data)\n",
    "\n",
    "    # Save to JSON file\n",
    "    with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(extracted_data, f, indent=4)\n",
    "\n",
    "    print(f\"✅ Data extracted and saved to {output_json}\")\n",
    "\n",
    "# Run extraction\n",
    "#extract_pdf_data(\"SBI Innovative Opportunities Fund_One Pager (2) (2).pdf\", \"extracted_data.json\")\n",
    "extract_pdf_data(\"Aatmanirbhar Org.pdf\", \"extracted_data.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0578690c",
   "metadata": {},
   "source": [
    "# Using  PyMyPDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9891d8e",
   "metadata": {},
   "source": [
    "# reconstruction of pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "922efd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Reconstructed PDF saved as reconstructed.pdf\n"
     ]
    }
   ],
   "source": [
    "# import fitz  # PyMuPDF\n",
    "# import json\n",
    "\n",
    "# def reconstruct_pdf_from_json(json_path, output_pdf):\n",
    "#     with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#         data = json.load(f)\n",
    "\n",
    "#     doc = fitz.open()\n",
    "\n",
    "#     for page_data in data:\n",
    "#         page = doc.new_page(width=page_data[\"width\"], height=page_data[\"height\"])\n",
    "\n",
    "#         for text_block in page_data[\"text_blocks\"]:\n",
    "#             for line in text_block[\"lines\"]:\n",
    "#                 for span in line[\"spans\"]:\n",
    "#                     text = span[\"text\"]\n",
    "#                     bbox = span[\"bbox\"]  # [x0, y0, x1, y1]\n",
    "#                     font_size = span[\"font_size\"]\n",
    "#                     font_name = span.get(\"font\", \"helv\")  # Default to Helvetica if font not found\n",
    "#                     rotation = span.get(\"rotation\", 30)\n",
    "\n",
    "#                     x0, y0, x1, y1 = bbox\n",
    "\n",
    "#                     # Calculate the bottom-left corner for the text insertion\n",
    "#                     insertion_point = fitz.Point(x0, y1)\n",
    "\n",
    "#                     # Insert text with rotation\n",
    "#                     page.insert_text(\n",
    "#                         insertion_point,\n",
    "#                         text,\n",
    "#                         #fontsize=font_size,\n",
    "#                         #fontname=font_name,\n",
    "#                         rotate=rotation\n",
    "#                     )\n",
    "\n",
    "#     doc.save(output_pdf)\n",
    "#     print(f\"✅ Reconstructed PDF saved as {output_pdf}\")\n",
    "\n",
    "# # Example usage\n",
    "# reconstruct_pdf_from_json(\"extracted_data.json\", \"reconstructed.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8d24b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Reconstructed PDF saved as reconstructed.pdf\n"
     ]
    }
   ],
   "source": [
    "# import fitz  # PyMuPDF\n",
    "# import json\n",
    "\n",
    "# def reconstruct_pdf_from_json(json_path, output_pdf):\n",
    "#     with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#         data = json.load(f)\n",
    "\n",
    "#     doc = fitz.open()\n",
    "\n",
    "#     for page_data in data:\n",
    "#         page = doc.new_page(width=page_data[\"width\"], height=page_data[\"height\"])\n",
    "\n",
    "#         for text_block in page_data[\"text_blocks\"]:\n",
    "#             for line in text_block[\"lines\"]:\n",
    "#                 for span in line[\"spans\"]:\n",
    "#                     text = span[\"text\"]\n",
    "#                     bbox = span[\"bbox\"]  # [x0, y0, x1, y1]\n",
    "#                     font_size = span[\"font_size\"]\n",
    "#                     font_name = span.get(\"font\", \"helv\")  # Default to Helvetica if font not found\n",
    "\n",
    "#                     x0, y0, x1, y1 = bbox\n",
    "\n",
    "#                     # Calculate the insertion point (bottom-left corner of the bounding box)\n",
    "#                     insertion_point = fitz.Point(x0, y1)\n",
    "\n",
    "#                     # Create a rotation matrix for 45 degrees\n",
    "#                     rotation_matrix = fitz.Matrix(45)\n",
    "\n",
    "#                     # Insert text with 45-degree rotation using the morph parameter\n",
    "#                     page.insert_text(\n",
    "#                         insertion_point,\n",
    "#                         text,\n",
    "#                         #fontsize=font_size,\n",
    "#                         #fontname=font_name,\n",
    "#                         morph=(insertion_point, rotation_matrix)\n",
    "#                     )\n",
    "\n",
    "#     doc.save(output_pdf)\n",
    "#     print(f\"✅ Reconstructed PDF saved as {output_pdf}\")\n",
    "\n",
    "# # Example usage\n",
    "# reconstruct_pdf_from_json(\"extracted_data.json\", \"reconstructed.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3c9a069f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Reconstructed PDF saved as reconstructed.pdf\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "\n",
    "def reconstruct_pdf_from_json(json_path, output_pdf):\n",
    "    # Load extracted data from JSON\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        extracted_data = json.load(f)\n",
    "\n",
    "    # Create a new PDF document\n",
    "    doc = fitz.open()\n",
    "\n",
    "    # Iterate through each page's data\n",
    "    for page_data in extracted_data:\n",
    "        # Create a new page with the same dimensions\n",
    "        page = doc.new_page(width=page_data[\"width\"], height=page_data[\"height\"])\n",
    "\n",
    "        # Iterate through text blocks\n",
    "        for block in page_data[\"text_blocks\"]:\n",
    "            # Iterate through lines\n",
    "            for line in block[\"lines\"]:\n",
    "                # Iterate through spans\n",
    "                for span in line[\"spans\"]:\n",
    "                    text = span[\"text\"]\n",
    "                    font_name = span[\"font\"]\n",
    "                    font_size = span[\"font_size\"]\n",
    "                    x0, y0, x1, y1 = span[\"bbox\"]\n",
    "                    rotation = span.get(\"rotation\", 0)\n",
    "\n",
    "                    # Calculate the insertion point (bottom-left corner of the bbox)\n",
    "                    insert_point = fitz.Point(x0, y1)\n",
    "\n",
    "                    # Create a transformation matrix for rotation around the insertion point\n",
    "                    transform_matrix = fitz.Matrix(rotation)\n",
    "\n",
    "                    # Insert the text with the transformation\n",
    "                    #page.insert_text(insert_point, text, fontsize=font_size, fontname=font_name, morph=(insert_point, transform_matrix))\n",
    "\n",
    "                    page.insert_text(\n",
    "                        insert_point,\n",
    "                        text,\n",
    "                        fontsize=font_size,\n",
    "                        #fontname=font_name,\n",
    "                        morph=(insert_point, transform_matrix)\n",
    "                    )\n",
    "    # Save the reconstructed PDF\n",
    "    doc.save(output_pdf)\n",
    "    print(f\"✅ Reconstructed PDF saved as {output_pdf}\")\n",
    "\n",
    "# Example usage\n",
    "reconstruct_pdf_from_json(\"extracted_data.json\", \"reconstructed.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6d7ed7",
   "metadata": {},
   "source": [
    "# Extracting image boxes and structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62db04aa",
   "metadata": {},
   "source": [
    "## preserve struct a little better sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "210033d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Text removed. New PDF saved as: sbi_output_no_text.pdf\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def remove_text_from_pdf(input_pdf, output_pdf):\n",
    "    # Open the PDF\n",
    "    doc = fitz.open(input_pdf)\n",
    "    \n",
    "    # Iterate through each page\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        \n",
    "        # Get all text blocks on the page\n",
    "        text_instances = page.get_text(\"dict\")\n",
    "        \n",
    "        # Iterate through each block\n",
    "        for block in text_instances[\"blocks\"]:\n",
    "            if \"lines\" in block:  # This block contains text\n",
    "                # Get the bounding box of the text block\n",
    "                rect = fitz.Rect(block[\"bbox\"])\n",
    "                \n",
    "                # Create a redaction annotation over the text block\n",
    "                page.add_redact_annot(rect)\n",
    "        \n",
    "        # Apply the redactions\n",
    "        page.apply_redactions()\n",
    "    \n",
    "    # Save the modified PDF\n",
    "    doc.save(output_pdf)\n",
    "    print(f\"✅ Text removed. New PDF saved as: {output_pdf}\")\n",
    "\n",
    "# Example usage\n",
    "#remove_text_from_pdf(\"Comic _Ghosts Book 1 Excerpt-6.pdf\", \"comic_no_text.pdf\")\n",
    "#remove_text_from_pdf(\"SBI Innovative Opportunities Fund_One Pager (2) (2).pdf\", \"sbi_output_no_text.pdf\")\n",
    "remove_text_from_pdf(\"Aatmanirbhar Org.pdf\", \"sbi_output_no_text.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1f1e39",
   "metadata": {},
   "source": [
    "# mapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1814a670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Text successfully mapped onto final_output.pdf\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "\n",
    "def overlay_text_on_pdf(input_pdf, json_path, output_pdf):\n",
    "    # Load extracted text data\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        extracted_data = json.load(f)\n",
    "\n",
    "    # Open the existing PDF (output_no_text.pdf)\n",
    "    doc = fitz.open(input_pdf)\n",
    "\n",
    "    for page_index, page_data in enumerate(extracted_data):\n",
    "        if page_index >= len(doc):  # Ensure we don't go out of bounds\n",
    "            break\n",
    "\n",
    "        page = doc[page_index]  # Get the existing page instead of creating a new one\n",
    "\n",
    "        for block in page_data[\"text_blocks\"]:\n",
    "            for line in block[\"lines\"]:\n",
    "                for span in line[\"spans\"]:\n",
    "                    text = span[\"text\"]\n",
    "                    font_size = span[\"font_size\"]\n",
    "                    font_name = span.get(\"font\", \"helv\")  # Default to Helvetica if missing\n",
    "                    x0, y0, x1, y1 = span[\"bbox\"]\n",
    "                    rotation = span.get(\"rotation\", 0)  # Extract rotation\n",
    "\n",
    "                    # Calculate the insertion point (bottom-left corner of the bounding box)\n",
    "                    insert_point = fitz.Point(x0, y1)\n",
    "\n",
    "                    # Apply the extracted rotation angle\n",
    "                    transform_matrix = fitz.Matrix(rotation)\n",
    "\n",
    "                    # Insert text on the existing page with transformation\n",
    "                    page.insert_text(\n",
    "                        insert_point,\n",
    "                        text,\n",
    "                        fontsize=font_size,\n",
    "                        #fontname=font_name,\n",
    "                        morph=(insert_point, transform_matrix)\n",
    "                    )\n",
    "\n",
    "    # Save the modified PDF\n",
    "    doc.save(output_pdf)\n",
    "    print(f\"✅ Text successfully mapped onto {output_pdf}\")\n",
    "\n",
    "# Example usage\n",
    "overlay_text_on_pdf(\"sbi_output_no_text.pdf\", \"extracted_data.json\", \"final_output.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca8e471",
   "metadata": {},
   "source": [
    "#### the new extracting is mapped (including the font color and boldness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c3bc00be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Text successfully mapped onto final_output.pdf\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "\n",
    "def overlay_text_on_pdf(input_pdf, json_path, output_pdf):\n",
    "    # Load extracted text data\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        extracted_data = json.load(f)\n",
    "\n",
    "    # Open the existing PDF (output_no_text.pdf)\n",
    "    doc = fitz.open(input_pdf)\n",
    "\n",
    "    for page_index, page_data in enumerate(extracted_data):\n",
    "        if page_index >= len(doc):  # Ensure we don't go out of bounds\n",
    "            break\n",
    "\n",
    "        page = doc[page_index]  # Get the existing page instead of creating a new one\n",
    "\n",
    "        for block in page_data[\"text_blocks\"]:\n",
    "            for line in block[\"lines\"]:\n",
    "                for span in line[\"spans\"]:\n",
    "                    text = span[\"text\"]\n",
    "                    font_size = span[\"font_size\"]\n",
    "                    font_name = span.get(\"font\", \"helv\")  # Default to Helvetica if missing\n",
    "                    x0, y0, x1, y1 = span[\"bbox\"]\n",
    "                    rotation = span.get(\"rotation\", 0)  # Extract rotation\n",
    "                    \n",
    "                    # Extract font color\n",
    "                    text_color = span.get(\"color\", (0, 0, 0))  # Default to black\n",
    "                    r, g, b = text_color  # Extract individual RGB values\n",
    "                    \n",
    "                    # Check if the font is bold\n",
    "                    is_bold = span.get(\"bold\", False)\n",
    "                    if is_bold:\n",
    "                        font_name += \"-Bold\"  # Append '-Bold' for bold fonts\n",
    "\n",
    "                    # Calculate the insertion point (bottom-left corner of the bounding box)\n",
    "                    insert_point = fitz.Point(x0, y1)\n",
    "\n",
    "                    # Apply the extracted rotation angle\n",
    "                    transform_matrix = fitz.Matrix(rotation)\n",
    "\n",
    "                    # Insert text on the existing page with transformation\n",
    "                    page.insert_text(\n",
    "                        insert_point,\n",
    "                        text,\n",
    "                        fontsize=font_size,\n",
    "                        #fontname=font_name,\n",
    "                        color=(r / 255, g / 255, b / 255),  # Normalize RGB (0-1)\n",
    "                        morph=(insert_point, transform_matrix)\n",
    "                    )\n",
    "\n",
    "    # Save the modified PDF\n",
    "    doc.save(output_pdf)\n",
    "    print(f\"✅ Text successfully mapped onto {output_pdf}\")\n",
    "\n",
    "# Example usage\n",
    "overlay_text_on_pdf(\"sbi_output_no_text.pdf\", \"extracted_data.json\", \"final_output.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811c2d26",
   "metadata": {},
   "source": [
    "# markdown of problematic pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8a2d17",
   "metadata": {},
   "source": [
    "# Introducing aatmanirbhar SIP  \n",
    "\n",
    "Aims to make you Aatmanirbhar to live the life you deserve  \n",
    "\n",
    "Systematic Investment Plan  \n",
    "\n",
    "![](https://cdn-mineru.openxlab.org.cn/extract/dc7c987f-552c-4156-941e-6f0e3af7b596/4a0d90beab56aae5c20ba1e9c173715f30e806d52de300d748dff6e3c4560453.jpg)  \n",
    "\n",
    "![](https://cdn-mineru.openxlab.org.cn/extract/dc7c987f-552c-4156-941e-6f0e3af7b596/f5e18922858f1494da94876d34ac9cb7d1959e88c27b99f9286d704e99d5a336.jpg)  \n",
    "\n",
    "## Illustration to explain concept of Aatmanirbhar SIP  \n",
    "\n",
    "simran began her journey towards financial independence in 2003 with a monthly SIP of  30,000 in Nifty 500 TRI benchmark she stayed invested for 10 years consistently, irrespective of market conditions and accumulated a corpus of approx 68 Lakl  \n",
    "\n",
    "![](https://cdn-mineru.openxlab.org.cn/extract/dc7c987f-552c-4156-941e-6f0e3af7b596/4fd6f84e71961a0ae8267a3a206d268a47a9d4bcce53366f79119d067dab0039.jpg)  \n",
    "\n",
    "![](https://cdn-mineru.openxlab.org.cn/extract/dc7c987f-552c-4156-941e-6f0e3af7b596/f60feca5356145f50acb9d07a29b0d9eeb4a2a9bcc2c0bf4de286a6e66600c2c.jpg)  \n",
    "\n",
    "![](https://cdn-mineru.openxlab.org.cn/extract/dc7c987f-552c-4156-941e-6f0e3af7b596/38e1987f62bc19beb77427007ed49c9f2cdabe6bd455df3ce6397722689cfe55.jpg)  \n",
    "\n",
    "## SWP  \n",
    "\n",
    "SimrandecidedtogowithSWPbecause it would provideher with passive income whilestillleavingherwith availablefunds.  \n",
    "\n",
    "<html><body><table><tr><td>InvestingSince</td><td>01/04/2003</td></tr><tr><td>SIPPermonth</td><td>30,000</td></tr><tr><td>InvestingPeriod(Yrs)</td><td>10</td></tr><tr><td>InvestedAmount</td><td>36,00,000</td></tr><tr><td>MarketValue(Apr1,2013)</td><td>68,87,718</td></tr><tr><td>SIPReturns(%XIRR)</td><td>12.40%</td></tr></table></body></html>  \n",
    "\n",
    "![](https://cdn-mineru.openxlab.org.cn/extract/dc7c987f-552c-4156-941e-6f0e3af7b596/a89d3f51061d01430abdbd24f40a599dcbad81abe2ef9642e7404138a93b8159.jpg)  \n",
    "Source:Bloomberg/axismfresearch.Dataason:30thMay,2023. Past performance may ormay not be sustainedinfuture.Thecalculation is a historicalcalculationofahypothetical 30000 monthlySIPinitiated on01/04/2003for10 years.Upon completion the corpusistransferredvia switchto NIFTY50 Hybrid CompositeDebt65:35Indexwith asubsequent systematicwithdrawal of $\\yen300000$ forthenext10years.Valueatth end ofthe period as of 30th April 2023.Expenses forthe execution, maintenance ofthefund and taxation have been ignored in thiscalculation. Theabove calculationsareonlyforilustrationpurposesand are subject tomarketrisksbased oncorpus at the end of the investment period actualmarket returnsand periodicity a cashflows.Thisfeature doesnotinanywaygive assuranceoftheperformance of any ofthe Schemes of Axis Mutual Fund or provide any guarantee of withdrawals through SWP mode. Investors are advised to consult their investment/taxadvisors beforeinvesting.  \n",
    "\n",
    "<html><body><table><tr><td rowspan=\"5\">Withdrawalsince MonthlyPayout Marketvalueatthestartofwithdrawal</td><td>01/04/2013</td></tr><tr><td>30,000</td></tr><tr><td>68,87,718</td></tr><tr><td>10</td></tr><tr><td>36,00,000</td></tr><tr><td>TotalMoneyWithdrawn Balancecorpusafter10years ofmonthlypayout</td><td>1,44,03,464</td></tr></table></body></html>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8af200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f460d533",
   "metadata": {},
   "source": [
    "# pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d56b8619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction complete. Data saved to extracted_text.json\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import json\n",
    "\n",
    "def extract_text_info(pdf_path):\n",
    "    extracted_data = []\n",
    "    \n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            for block in page.extract_words():\n",
    "                data = {\n",
    "                    \"left\": block[\"x0\"],\n",
    "                    \"top\": block[\"top\"],\n",
    "                    \"end_left\": block[\"x1\"],\n",
    "                    \"end_top\": block[\"bottom\"],\n",
    "                    \"total_texts\": 1,\n",
    "                    \"is_bullet\": False,\n",
    "                    \"type\": \"normal\",\n",
    "                    \"text1\": \"\",\n",
    "                    \"text\": block[\"text\"],\n",
    "                    \"font_family\": \"Unknown\",  # pdfplumber doesn't extract font family\n",
    "                    \"font_size\": 8.0,  # Adjust if needed\n",
    "                    \"font_color\": 0,  # Requires extra processing\n",
    "                    \"font_color_hex\": \"#000000\",\n",
    "                    \"font_style\": \"normal\",\n",
    "                    \"is_vertical\": False,\n",
    "                    \"angle\": 0,\n",
    "                    \"superscript\": False\n",
    "                }\n",
    "                extracted_data.append(data)\n",
    "    \n",
    "    return extracted_data\n",
    "\n",
    "pdf_path = \"Aatmanirbhar Org.pdf\"  # Replace with the actual file path\n",
    "data = extract_text_info(pdf_path)\n",
    "\n",
    "# Save as JSON\n",
    "with open(\"extracted_text.json\", \"w\") as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "\n",
    "print(\"Extraction complete. Data saved to extracted_text.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c870e955",
   "metadata": {},
   "source": [
    "# MEET THE INNOVATORS WHO WILL POWER NEXT GEN INDIA  \n",
    "\n",
    "![](https://cdn-mineru.openxlab.org.cn/extract/c0da4e40-b104-4816-9e2d-01cc8618cf3f/21bdc3896e18f5c84f4d7a94c16be36c00969f2aa6ff49378e2bdabf53d9ca84.jpg)  \n",
    "\n",
    "नवाचार नए विचारों, प्रौद्योगिकियों और प्रक्रियाओं को प्रस्तुत करके विकास को गति देता है, जो परंपरागत मानदंडों को चुनौती देते हैं। जो कंपनियां नवाचार को अपनाती हैं, वे प्रतिस्पर्धात्मक बढ़त प्राप्त करती हैं और अपने क्षेत्रों के भविष्य को आकार देती हैं।\n",
    "\n",
    "\n",
    "![](https://cdn-mineru.openxlab.org.cn/extract/c0da4e40-b104-4816-9e2d-01cc8618cf3f/d79ea84e2ea7f1df0dee5ddb9afe75ac45b9324507f6441077bbeb1551a2e2a5.jpg)  \n",
    "\n",
    "## FACTORSINFLUENCINGINDIAINNOVATIONSTORY  \n",
    "\n",
    "$\\odot$ Booming Startup Ecosystem $\\circledcirc$ Inherent Talent Pool OGovernment Initiatives  \n",
    "\n",
    "$\\odot$ Growing Consumer Market $\\pmb{\\odot}$ Strong Digital Infrastructure $\\pmb{\\odot}$ Strong Funding Ecosystem  \n",
    "\n",
    "ndia's position in the Global Innovation Index\\* has improved to $40^{\\mathrm{th}}$ rank in 2023 from $81^{\\mathrm{st}}$ in 2015. Due to the above favorable tailwinds, we believe ndia is currently at the cusp of an innovation cycle.  \n",
    "\n",
    "Source: SBIMF Research.\\* Published by the World Intellectual Property Organization  \n",
    "\n",
    "## भारत की नवाचार कहानी को प्रभावित करने वाले कारक  \n",
    "\n",
    "$\\odot$ फलता-फूलता स्टार्टअप इकोसिस्टम \\\\  \n",
    "$\\circledcirc$ स्वाभाविक प्रतिभा पूल \\\\  \n",
    "\n",
    "Oसरकारी पहल \\\\  \n",
    "$\\odot$ बढ़ता उपभोक्ता बाजार \\\\  \n",
    "\n",
    "$\\pmb{\\odot}$ मजबूत डिजिटल अवसंरचना \\\\  \n",
    "$\\pmb{\\odot}$ मजबूत वित्तीय पारिस्थितिकी तंत्र \\\\  \n",
    "\n",
    "भारत की वैश्विक नवाचार सूचकांक\\* में स्थिति 2015 में $81^{\\mathrm{st}}$ स्थान से सुधार कर 2023 में $40^{\\mathrm{th}}$ स्थान पर पहुंच गई है।  \n",
    "\n",
    "उपरोक्त अनुकूल परिस्थितियों के कारण, हमें विश्वास है कि भारत वर्तमान में एक नवाचार चक्र के कगार पर है।  \n",
    "\n",
    "स्रोत: SBIMF अनुसंधान।\\* विश्व बौद्धिक संपदा संगठन द्वारा प्रकाशित  \n",
    "\n",
    "## भारत की नवाचार कहानी को प्रभावित करने वाले कारक  \n",
    "\n",
    "$\\odot$ फलता-फूलता स्टार्टअप इकोसिस्टम \\ \\ $\\circledcirc$ स्वाभाविक प्रतिभा पूल \\\\  \n",
    "\n",
    "Oसरकारी पहल \\ \\ $\\odot$ बढ़ता उपभोक्ता बाजार \\\\  \n",
    "\n",
    "$\\pmb{\\odot}$ मजबूत डिजिटल अवसंरचना \\ \\ $\\pmb{\\odot}$ मजबूत वित्तीय पारिस्थितिकी तंत्र \\\\  \n",
    "\n",
    "भारत की वैश्विक नवाचार सूचकांक\\* में स्थिति 2015 में $81^{\\mathrm{st}}$ स्थान से सुधार कर 2023 में $40^{\\mathrm{th}}$ स्थान पर पहुंच गई है।  \n",
    "\n",
    "उपरोक्त अनुकूल परिस्थितियों के कारण, हमें विश्वास है कि भारत वर्तमान में एक नवाचार चक्र के कगार पर है।  \n",
    "\n",
    "स्रोत: SBIMF अनुसंधान।\\* विश्व बौद्धिक संपदा संगठन द्वारा प्रकाशित  \n",
    "\n",
    "## भारत की नवाचार कहानी को प्रभावित करने वाले कारक  \n",
    "\n",
    "$\\odot$ फलता-फूलता स्टार्टअप इकोसिस्टम \\ \\ $\\circledcirc$ स्वाभाविक प्रतिभा पूल \\\\  \n",
    "\n",
    "Oसरकारी पहल \\ \\ $\\odot$ बढ़ता उपभोक्ता बाजार \\\\  \n",
    "\n",
    "$\\pmb{\\odot}$ मजबूत डिजिटल अवसंरचना \\ \\ $\\pmb{\\odot}$ मजबूत वित्तीय पारिस्थितिकी तंत्र \\\\  \n",
    "\n",
    "भारत की वैश्विक नवाचार सूचकांक\\* में स्थिति 2015 में $81^{\\mathrm{st}}$ स्थान से सुधार कर 2023 में $40^{\\mathrm{th}}$ स्थान पर पहुंच गई है।  \n",
    "\n",
    "उपरोक्त अनुकूल परिस्थितियों के कारण, हमें विश्वास है कि भारत वर्तमान में एक नवाचार चक्र के कगार पर है।  \n",
    "\n",
    "स्रोत: SBIMF अनुसंधान।\\* विश्व बौद्धिक संपदा संगठन द्वारा प्रकाशित  \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## O INVESTMENTSTRATEGY  \n",
    "\n",
    "![](https://cdn-mineru.openxlab.org.cn/extract/c0da4e40-b104-4816-9e2d-01cc8618cf3f/f7cb8897434809ed9a071735adeecf1023221f4a05a07176bf313e556f6b5159.jpg)  \n",
    "\n",
    "<span>\n",
    "<bold>Product / Service Innovators :<bold> Companies that develop new products or services or significantly invest in R&D for new innovations.   \n",
    "They challenge existing markets or create entirely new categories.  \n",
    "\n",
    "Process Innovators : Companies that innovate new processes, potentially disrupting existing business models and gaining market share through technological and process advancements.  \n",
    "\n",
    "InnovationAdaptors $:$ Incumbent companies that adapt to innovative business models, products, or services within their industry, showing agility in response to emergent trends. These adaptive innovators may not necessarily overhaul their entire business model but exhibit innovative strategies in specific segments or verticals that has potential to meaningfully impact the business.  \n",
    "\n",
    "Each category presents opportunities and rsks, which wil guide investment decisions. For detailed investmentstrategy please refer Scheme Information Document carefully.  \n",
    "\n",
    "### PORTFOLIOCONSTRUCTIONAPPROACH  \n",
    "\n",
    "·Min $80\\%$ of net assets investing into companies falling into innovation theme buckets   \n",
    "$\\bullet$ Upto $35\\%$ of net assets investing into global stocks aligned with the underlying theme   \n",
    "$\\bullet$ True to its label diversified portfolio investing across sectors & Market cap   \n",
    "$\\bullet$ Aims to have a portfolio of \\~35-40 stocks with bottom-up stock selection approach Companies with long runway for growth, competitive advantage, potential for generating strong ROE & cashflows etc  \n",
    "\n",
    "Further, to achieve diversification the Scheme may also invest residual net assets i.e. up to $20\\%$ of the net assets in companies other than the companies following innovation theme This is based on the prevailing market conditions & current views and is subject to change within the limits of the SiD basis the fund manager's view.  \n",
    "\n",
    "### O WHOCANINVESTINSBIINNOVATIVEOPPORTUNITIESFUND?  \n",
    "\n",
    "![](https://cdn-mineru.openxlab.org.cn/extract/c0da4e40-b104-4816-9e2d-01cc8618cf3f/bea6b342ed91c5ae2031fafc4b8a8c6fae9c2e96b343f8072ee3a3b36d6da4a3.jpg)  \n",
    "\n",
    "#  \n",
    "\n",
    "Investors looking for a fund that consistently seeks out investment opportunities in upcoming trends and disruptive business ideas will find this fund true to label. Investors seeking capital appreciation through investments in forward-looking business ideas and a growth-oriented long-term portfolio 2 willfind this fund appealing. Investors seeking diversification through portfolio allocation across sectors and market caps, offering a unique avenue to tap into emerging trends and markets.  \n",
    "\n",
    "### ABOUTSBIINNOVATIVEOPPORTUNITIESFUND  \n",
    "\n",
    "#### Investment Objective:  \n",
    "\n",
    "The investment objective of the scheme is to provide investors with opportunities for long term capital appreciation by investing in equity and equity related instruments of companies that seeks to benefit from adoption of innovative strategies & theme. However, there can be no assurance that the investment objective of the Scheme will be realized.  \n",
    "\n",
    "· Fund Manager&: Mr. Prasad Padala · Category: Thematic · Minimum Application^: 50o0/- & in multiples of $\\yen1$ thereafter · First Tier Banchmark Index: NIFTY 500 TRI $\\bullet$ MinimumMonthly ${\\mathsf{s l P}}^{\\star}$ :?500/-& inmultiples of 1  \n",
    "\n",
    "#### Exit Load:  \n",
    "\n",
    "·ForOngoingbasis: $1\\%$ of theapplicableNAv $\\cdot$ If units purchased or switched in from another scheme of the fund are redeemed or switched out onorbefore1yearfromthedateof allotment. · NIL - If units purchased or switched in from another scheme of the fund are redeemed or switched out after 1 year from the date of allotment.  \n",
    "\n",
    "For details, please refer to the Scheme Information Document (SiD). &Mr. Pradeep Kesavan is the dedicated fund manager for overseas securities. ^Additional Purchase: Rs. 1000 and in multiples of Re.1 thereafter. \\*For detailed minimum amount of SIP across frequencies & number of installments, please refer to SID/KIM.  \n",
    "\n",
    "## SBI INNOVATIVE OPPORTUNITIES FUND  \n",
    "\n",
    "![](https://cdn-mineru.openxlab.org.cn/extract/c0da4e40-b104-4816-9e2d-01cc8618cf3f/a8f17133806929132e9e018f3f86a56f0071c7539257951d39851fdf380df56a.jpg)  \n",
    "\n",
    "An open-ended equity scheme following the innovationtheme.  \n",
    "\n",
    "This leaflet is for information purposes only and is not an offer to sell or a solicitation to buy any mutual fund units/securities. The views expressed herein are based on the basis of internal data, publicly available information & other sources believed to be reliable. Any calculations made are approximations meant as guidelines only, which need to be confirmed before relying on them. These views alone are not sufficient and should not be used for the development or implementation of an investment strategy. It should not be construed as investment advice to any party. All opinions and estimates included here constitute our view as of this date and are subject to change without notice. Neither SBl Funds Management Limited, SBI Mutual Fund nor any person connected with it, accepts any liability arising from the use of this information. The recipient of this material should rely on their investigations and take their own professional advice.  \n",
    "\n",
    "# Contact your MFD/RIA Visit: www.sbimf.com Follow us: +×回 in  \n",
    "\n",
    "Mutual Fund investments are subject to market risks, read all scheme related documents carefully.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa1044f",
   "metadata": {},
   "source": [
    "# miner u api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3e6cb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "x = \"eyJ0eXBlIjoiSldUIiwiYWxnIjoiSFM1MTIifQ.eyJqdGkiOiIyMTAwMjc3NSIsInJvbCI6IlJPTEVfUkVHSVNURVIiLCJpc3MiOiJPcGVuWExhYiIsImlhdCI6MTc0MTg2ODk5NSwiY2xpZW50SWQiOiJsa3pkeDU3bnZ5MjJqa3BxOXgydyIsInBob25lIjoiIiwidXVpZCI6ImM2YWExZjk2LTY5ZjMtNDNlMC1hYzcyLTU1MWM4YzA1Y2ZmNyIsImVtYWlsIjoiIiwiZXhwIjoxNzQzMDc4NTk1fQ.oSJ_jubwoX14Pji1gOi2kUaYCTv4GWRSmyNp4O5jkJ8jXG-wYFN_s03n5Iy8JOUGn9hVOuzVP4QZMdCBSHXIvA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72399795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eyJ0eXBlIjoiSldUIiwiYWxnIjoiSFM1MTIifQ.eyJqdGkiOiIyMTAwMjc3NSIsInJvbCI6IlJPTEVfUkVHSVNURVIiLCJpc3MiOiJPcGVuWExhYiIsImlhdCI6MTc0MTg2ODk5NSwiY2xpZW50SWQiOiJsa3pkeDU3bnZ5MjJqa3BxOXgydyIsInBob25lIjoiIiwidXVpZCI6ImM2YWExZjk2LTY5ZjMtNDNlMC1hYzcyLTU1MWM4YzA1Y2ZmNyIsImVtYWlsIjoiIiwiZXhwIjoxNzQzMDc4NTk1fQ.oSJ_jubwoX14Pji1gOi2kUaYCTv4GWRSmyNp4O5jkJ8jXG-wYFN_s03n5Iy8JOUGn9hVOuzVP4QZMdCBSHXIvA'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01f9656",
   "metadata": {},
   "source": [
    "using the api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28459774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401\n",
      "{'traceId': 'e7f6db99b052', 'msgCode': 'A0202', 'msg': 'user authenticate failed', 'data': None, 'success': False, 'total': 0}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url='https://mineru.net/api/v4/extract/task'\n",
    "header = {\n",
    "    'Content-Type':'application/json',\n",
    "    \"Authorization\":'eyJ0eXBlIjoiSldUIiwiYWxnIjoiSFM1MTIifQ.eyJqdGkiOiIyMTAwMjc3NSIsInJvbCI6IlJPTEVfUkVHSVNURVIiLCJpc3MiOiJPcGVuWExhYiIsImlhdCI6MTc0MTg2OTQxNiwiY2xpZW50SWQiOiJsa3pkeDU3bnZ5MjJqa3BxOXgydyIsInBob25lIjoiIiwidXVpZCI6IjlmMWQ4ZmJiLTk5MzgtNDFiMy05MDZjLTcxNWYzNDFkN2U2YSIsImVtYWlsIjoiIiwiZXhwIjoxNzQzMDc5MDE2fQ.lIh5brncncJgioW3d_oyTgTy5PTOh7aNGlEP_uLgpFYCndSZYp0aqrnnnbdtO2WPPcKGyTp3BYCaUP_nMV5AAA'\n",
    "}\n",
    "data = {\n",
    "    'url':'https://cdn-mineru.openxlab.org.cn/demo/example.pdf',\n",
    "    'is_ocr':True,\n",
    "    'enable_formula': False,\n",
    "}\n",
    "\n",
    "res = requests.post(url,headers=header,json=data)\n",
    "print(res.status_code)\n",
    "print(res.json())\n",
    "print(res.json()[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb04376",
   "metadata": {},
   "source": [
    "eyJ0eXBlIjoiSldUIiwiYWxnIjoiSFM1MTIifQ.eyJqdGkiOiIyMTAwMjc3NSIsInJvbCI6IlJPTEVfUkVHSVNURVIiLCJpc3MiOiJPcGVuWExhYiIsImlhdCI6MTc0MTg2OTQxNiwiY2xpZW50SWQiOiJsa3pkeDU3bnZ5MjJqa3BxOXgydyIsInBob25lIjoiIiwidXVpZCI6IjlmMWQ4ZmJiLTk5MzgtNDFiMy05MDZjLTcxNWYzNDFkN2U2YSIsImVtYWlsIjoiIiwiZXhwIjoxNzQzMDc5MDE2fQ.lIh5brncncJgioW3d_oyTgTy5PTOh7aNGlEP_uLgpFYCndSZYp0aqrnnnbdtO2WPPcKGyTp3BYCaUP_nMV5AAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ab4e25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response not success. status:401 ,result:<Response [401]>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url='https://mineru.net/api/v4/file-urls/batch'\n",
    "header = {\n",
    "    'Content-Type':'application/json',\n",
    "    \"Authorization\":x\n",
    "}\n",
    "data = {\n",
    "    \"enable_formula\": True,\n",
    "    \"language\": \"en\",\n",
    "    \"layout_model\":\"doclayout_yolo\",\n",
    "    \"enable_table\": True,\n",
    "    \"files\": [\n",
    "        {\"name\":\"demo.pdf\", \"is_ocr\": True, \"data_id\": \"abcd\"}\n",
    "    ]\n",
    "}\n",
    "file_path = r\"demo.pdf\"\n",
    "try:\n",
    "    response = requests.post(url,headers=header,json=data)\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        print('response success. result:{}'.format(result))\n",
    "        if result[\"code\"] == 0:\n",
    "            batch_id = result[\"data\"][\"batch_id\"]\n",
    "            urls = result[\"data\"][\"file_urls\"]\n",
    "            print('batch_id:{},urls:{}'.format(batch_id, urls))\n",
    "            with open(file_path, 'rb') as f:\n",
    "                res_upload = requests.put(urls[0], data=f)\n",
    "            if res_upload.status_code == 200:\n",
    "                print(\"upload success\")\n",
    "            else:\n",
    "                print(\"upload failed\")\n",
    "        else:\n",
    "            print('apply upload url failed,reason:{}'.format(result.msg))\n",
    "    else:\n",
    "        print('response not success. status:{} ,result:{}'.format(response.status_code, response))\n",
    "except Exception as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9194a61",
   "metadata": {},
   "source": [
    "# Tesseract ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "049ae60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.cloud import vision\n",
    "# import io\n",
    "# import requests\n",
    "\n",
    "# def google_vision_ocr(image_url):\n",
    "#     \"\"\"Extract text from an image using Google Cloud Vision API\"\"\"\n",
    "#     client = vision.ImageAnnotatorClient()\n",
    "\n",
    "#     # Download the image\n",
    "#     response = requests.get(image_url)\n",
    "#     image = vision.Image(content=response.content)\n",
    "\n",
    "#     # Perform text detection\n",
    "#     result = client.text_detection(image=image)\n",
    "#     texts = result.text_annotations\n",
    "\n",
    "#     extracted_text = texts[0].description if texts else \"No text found\"\n",
    "\n",
    "#     print(\"Extracted Text:\")\n",
    "#     print(extracted_text)\n",
    "\n",
    "# # 🔹 Call the function with your image URL\n",
    "# image_url = \"https://cdn-mineru.openxlab.org.cn/extract/c0da4e40-b104-4816-9e2d-01cc8618cf3f/21bdc3896e18f5c84f4d7a94c16be36c00969f2aa6ff49378e2bdabf53d9ca84.jpg\"\n",
    "# google_vision_ocr(image_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e53dd1e",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28b10693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"left\": 227.0359000000003,\n",
      "    \"top\": 475.2403999999999,\n",
      "    \"end_left\": 275.6119000000004,\n",
      "    \"end_top\": 483.2403999999999,\n",
      "    \"total_texts\": 1,\n",
      "    \"is_bullet\": false,\n",
      "    \"type\": \"normal\",\n",
      "    \"text1\": \"\",\n",
      "    \"text\": \"technologies, and processes\",\n",
      "    \"font_family\": \"Unknown\",\n",
      "    \"font_size\": 8.0,\n",
      "    \"font_color\": 0,\n",
      "    \"font_color_hex\": \"#000000\",\n",
      "    \"font_style\": \"normal\",\n",
      "    \"is_vertical\": false,\n",
      "    \"angle\": 0,\n",
      "    \"superscript\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Given JSON objects\n",
    "json_objects = [\n",
    "    {\n",
    "        \"left\": 227.0359000000003,\n",
    "        \"top\": 475.2403999999999,\n",
    "        \"end_left\": 275.6119000000004,\n",
    "        \"end_top\": 483.2403999999999,\n",
    "        \"total_texts\": 1,\n",
    "        \"is_bullet\": False,\n",
    "        \"type\": \"normal\",\n",
    "        \"text1\": \"\",\n",
    "        \"text\": \"technologies,\",\n",
    "        \"font_family\": \"Unknown\",\n",
    "        \"font_size\": 8.0,\n",
    "        \"font_color\": 0,\n",
    "        \"font_color_hex\": \"#000000\",\n",
    "        \"font_style\": \"normal\",\n",
    "        \"is_vertical\": False,\n",
    "        \"angle\": 0,\n",
    "        \"superscript\": False\n",
    "    },\n",
    "    {\n",
    "        \"left\": 278.17430000000047,\n",
    "        \"top\": 475.2403999999999,\n",
    "        \"end_left\": 291.7583000000004,\n",
    "        \"end_top\": 483.2403999999999,\n",
    "        \"total_texts\": 1,\n",
    "        \"is_bullet\": False,\n",
    "        \"type\": \"normal\",\n",
    "        \"text1\": \"\",\n",
    "        \"text\": \"and\",\n",
    "        \"font_family\": \"Unknown\",\n",
    "        \"font_size\": 8.0,\n",
    "        \"font_color\": 0,\n",
    "        \"font_color_hex\": \"#000000\",\n",
    "        \"font_style\": \"normal\",\n",
    "        \"is_vertical\": False,\n",
    "        \"angle\": 0,\n",
    "        \"superscript\": False\n",
    "    },\n",
    "    {\n",
    "        \"left\": 294.32150000000047,\n",
    "        \"top\": 475.2403999999999,\n",
    "        \"end_left\": 331.73750000000047,\n",
    "        \"end_top\": 483.2403999999999,\n",
    "        \"total_texts\": 1,\n",
    "        \"is_bullet\": False,\n",
    "        \"type\": \"normal\",\n",
    "        \"text1\": \"\",\n",
    "        \"text\": \"processes\",\n",
    "        \"font_family\": \"Unknown\",\n",
    "        \"font_size\": 8.0,\n",
    "        \"font_color\": 0,\n",
    "        \"font_color_hex\": \"#000000\",\n",
    "        \"font_style\": \"normal\",\n",
    "        \"is_vertical\": False,\n",
    "        \"angle\": 0,\n",
    "        \"superscript\": False\n",
    "    }\n",
    "]\n",
    "\n",
    "# Given sentences\n",
    "sentences = [\"technologies, and processes\", \"some other sentence\"]\n",
    "\n",
    "# Step 1: Extract words from JSON\n",
    "word_sequence = \" \".join([obj[\"text\"] for obj in json_objects])\n",
    "\n",
    "# Step 2: Find which words belong to a sentence\n",
    "matching_sentence = None\n",
    "for sentence in sentences:\n",
    "    if sentence in word_sequence:\n",
    "        matching_sentence = sentence\n",
    "        break\n",
    "\n",
    "# Step 3: Create new JSON object using attributes of the first word\n",
    "if matching_sentence:\n",
    "    first_obj = json_objects[0]  # Take attributes from the first word object\n",
    "    new_json_object = first_obj.copy()  # Clone it\n",
    "    new_json_object[\"text\"] = matching_sentence  # Replace text with the full sentence\n",
    "\n",
    "    # Output result\n",
    "    print(json.dumps(new_json_object, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c84bd39",
   "metadata": {},
   "source": [
    "# Text returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c20416",
   "metadata": {},
   "source": [
    "\n",
    "<span>\n",
    "<bold>Product / Service Innovators :<bold> Companies that develop new products or services or significantly invest in R&D for new innovations.   \n",
    "They challenge existing markets or create entirely new categories.  \n",
    "\n",
    "Process Innovators : Companies that innovate new processes, potentially disrupting existing business models and gaining market share through technological and process advancements.  \n",
    "\n",
    "InnovationAdaptors $:$ Incumbent companies that adapt to innovative business models, products, or services within their industry, showing agility in response to emergent trends. These adaptive innovators may not necessarily overhaul their entire business model but exhibit innovative strategies in specific segments or verticals that has potential to meaningfully impact the business.  \n",
    "\n",
    "Each category presents opportunities and rsks, which wil guide investment decisions. For detailed investmentstrategy please refer Scheme Information Document carefully.  \n",
    "\n",
    "### PORTFOLIOCONSTRUCTIONAPPROACH  \n",
    "\n",
    "·Min $80\\%$ of net assets investing into companies falling into innovation theme buckets   \n",
    "$\\bullet$ Upto $35\\%$ of net assets investing into global stocks aligned with the underlying theme   \n",
    "$\\bullet$ True to its label diversified portfolio investing across sectors & Market cap   \n",
    "$\\bullet$ Aims to have a portfolio of \\~35-40 stocks with bottom-up stock selection approach Companies with long runway for growth, competitive advantage, potential for generating strong ROE & cashflows etc  \n",
    "\n",
    "Further, to achieve diversification the Scheme may also invest residual net assets i.e. up to $20\\%$ of the net assets in companies other than the companies following innovation theme This is based on the prevailing market conditions & current views and is subject to change within the limits of the SiD basis the fund manager's view.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeca2be1",
   "metadata": {},
   "source": [
    "# LLm processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2404515",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Product / Service Innovators: Companies that develop new products or services or significantly invest in R&D for new innovations. They challenge existing markets or create entirely new categories.\",\n",
    "    \"Process Innovators: Companies that innovate new processes, potentially disrupting existing business models and gaining market share through technological and process advancements.\",\n",
    "    \"Innovation Adaptors: Incumbent companies that adapt to innovative business models, products, or services within their industry, showing agility in response to emergent trends. These adaptive innovators may not necessarily overhaul their entire business model but exhibit innovative strategies in specific segments or verticals that have the potential to meaningfully impact the business.\",\n",
    "    \"Each category presents opportunities and risks, which will guide investment decisions.\",\n",
    "    \"For a detailed investment strategy, please refer to the Scheme Information Document carefully.\",\n",
    "    \"Portfolio Construction Approach: At least 80% of net assets will be invested in companies falling into innovation theme buckets.\",\n",
    "    \"Up to 35% of net assets will be invested in global stocks aligned with the underlying theme.\",\n",
    "    \"The portfolio will be diversified, investing across sectors and market capitalization.\",\n",
    "    \"The fund aims to maintain a portfolio of approximately 35-40 stocks with a bottom-up stock selection approach.\",\n",
    "    \"Companies with a long runway for growth, competitive advantage, and potential for generating strong ROE and cash flows will be prioritized.\",\n",
    "    \"To achieve diversification, the scheme may invest up to 20% of net assets in companies outside the innovation theme based on prevailing market conditions and fund manager discretion.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892c3ba8",
   "metadata": {},
   "source": [
    "![](https://cdn-mineru.openxlab.org.cn/extract/c0da4e40-b104-4816-9e2d-01cc8618cf3f/d79ea84e2ea7f1df0dee5ddb9afe75ac45b9324507f6441077bbeb1551a2e2a5.jpg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc29bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Function to perform OCR\n",
    "def extract_text_from_image(image_url):\n",
    "    # Download image from URL\n",
    "    response = requests.get(image_url)\n",
    "    image = Image.open(BytesIO(response.content))\n",
    "\n",
    "    # Perform OCR\n",
    "    extracted_text = pytesseract.image_to_string(image)\n",
    "\n",
    "    print(\"Extracted Text:\")\n",
    "    print(extracted_text)\n",
    "\n",
    "# Test with your image URL\n",
    "image_url = \"https://cdn-mineru.openxlab.org.cn/extract/c0da4e40-b104-4816-9e2d-01cc8618cf3f/d79ea84e2ea7f1df0dee5ddb9afe75ac45b9324507f6441077bbeb1551a2e2a5.jpg\"\n",
    "extract_text_from_image(image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8dcd3a",
   "metadata": {},
   "source": [
    "Automobiles\n",
    "\n",
    "Electric Vehicles\n",
    "Self Drive cars\n",
    "Hybrid vehicles\n",
    "Energy\n",
    "\n",
    "Hydrogen\n",
    "Battery Storage\n",
    "Grid integration\n",
    "Media & Entertainment\n",
    "\n",
    "OTT\n",
    "Digital Content & Ads\n",
    "Music streaming\n",
    "Industrials\n",
    "\n",
    "Robots & Drones\n",
    "3D printing\n",
    "Nanotechnology\n",
    "Financial Services\n",
    "\n",
    "UPI\n",
    "Block chain\n",
    "Payment Aggregator\n",
    "Consumption\n",
    "\n",
    "Quick Commerce\n",
    "Augmented reality\n",
    "Omnichannel integration\n",
    "Technology\n",
    "\n",
    "Cloud computing\n",
    "AI & IoT\n",
    "Data centers\n",
    "Healthcare\n",
    "\n",
    "Medtech\n",
    "E-Pharmacy\n",
    "Biotechnology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21bf0954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Automobiles: Electric Vehicles, Self Drive cars, Hybrid vehicles', 'Energy: Hydrogen, Battery Storage, Grid integration', 'Media & Entertainment: OTT, Digital Content & Ads, Music streaming', 'Industrials: Robots & Drones, 3D printing, Nanotechnology', 'Financial Services: UPI, Block chain, Payment Aggregator', 'Consumption: Quick Commerce, Augmented reality, Omnichannel integration', 'Technology: Cloud computing, AI & IoT, Data centers', 'Healthcare: Medtech, E-Pharmacy, Biotechnology']\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    \"Automobiles: Electric Vehicles, Self Drive cars, Hybrid vehicles\",\n",
    "    \"Energy: Hydrogen, Battery Storage, Grid integration\",\n",
    "    \"Media & Entertainment: OTT, Digital Content & Ads, Music streaming\",\n",
    "    \"Industrials: Robots & Drones, 3D printing, Nanotechnology\",\n",
    "    \"Financial Services: UPI, Block chain, Payment Aggregator\",\n",
    "    \"Consumption: Quick Commerce, Augmented reality, Omnichannel integration\",\n",
    "    \"Technology: Cloud computing, AI & IoT, Data centers\",\n",
    "    \"Healthcare: Medtech, E-Pharmacy, Biotechnology\"\n",
    "]\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48ea7a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
